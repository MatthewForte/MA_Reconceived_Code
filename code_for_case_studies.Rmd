---
title: "Case Studies"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Note that all code is publicly available at https://github.com/MatthewForte/MA_Reconceived_Code.

# Import Libraries

```{r}
library(metafor)
library(dplyr)
library(tidyr)
library(rcompanion)
```

# Example 1

```{r}
# Read in data
ex_1_data <- read.csv("Example_1_data_cleaned.csv")

# Clean to only include non-empty rows - Tables 2 and 3
ex_1_data <- ex_1_data[1:4, ]

# Change column names
names <- c("review_id", "citation", "intervention", "frl", "grade", "black", 
           "white", "other", "state", "ni", "ni_t", "ni_c", "g", "p_val", "Ni")

colnames(ex_1_data) <- names

# Change data types
ex_1_data$g <- as.numeric(ex_1_data$g)
```

Next, we need to add the within study variance. Our effect sizes are all Hedge's g, and the variance of this is function of Cohen's d ($d$) and a small-sample bias correction factor ($J$), where $g = Jd$.

$$
v_i = Var(g) 
\\= J^2Var(d)
\\= J^2[\frac{n_i}{n_tn_c} + \frac{d^2}{2(n_i-2)}]
\\=J^2[\frac{n_i}{n_tn_c} + \frac{g^2}{2J^2(n_i-2)}]
\\=J^2[\frac{n_i}{n_tn_c}] + \frac{g^2}{2(n-2)}
$$
where

$$
J = 1 - \frac{3}{4df-1}
\\= 1 - \frac{3}{4(n_i - 2) - 1}
$$


```{r}
# Add within study variance for each study
J <- 1 - (3 / (4*(ex_1_data$ni - 2) - 1))
vi <- ((J^2) * (ex_1_data$ni / (ex_1_data$ni_c * ex_1_data$ni_t))) + 
  ((ex_1_data$g^2) / (2*(ex_1_data$ni - 2)))

ex_1_data$vi <- vi

# Get data in terms of counts and not percentages for covariates
count_data <- ex_1_data[, c("review_id", "frl", "black", "white", "other", "ni")]

# Converting percentages to counts based on sample size for each study
  # Assuming percentages each study reports are rounded to nearest whole number
count_data <- count_data %>%
  rowwise() %>%
  mutate(
    count_frl=list(c(rep(1, round((frl/100*ni))), rep(0, ni - round((frl/100*ni))))),
    count_black=list(c(rep(1, round((black/100*ni))), rep(0, ni - round((black/100*ni))))),
    count_white=list(c(rep(1, round((white/100*ni))), rep(0, ni - round((white/100*ni))))),
    count_other=list(c(rep(1, round((other/100*ni))), rep(0, ni - round((other/100*ni)))))
  ) %>%
  unnest(c(count_frl, count_black, count_white, count_other))

count_data <- count_data[, c("review_id", "count_frl", "count_black", "count_white", "count_other")]

# Determining if there is clustering or grouping
  # Chi-squared tests on covariates and Cramer's V - Table 4
chisq.test(table(count_data$review_id, count_data$count_frl))
chisq.test(table(count_data$review_id, count_data$count_black))
chisq.test(table(count_data$review_id, count_data$count_white))
chisq.test(table(count_data$review_id, count_data$count_other))

cramerV(table(count_data$review_id, count_data$count_frl))
cramerV(table(count_data$review_id, count_data$count_black))
cramerV(table(count_data$review_id, count_data$count_white))
cramerV(table(count_data$review_id, count_data$count_other))

# Performing meta-analyses - Table 5
  # FES - WWC
fes_ma <- rma(yi=g, vi=vi, method="FE", data=ex_1_data)
fes_estimate <- fes_ma$beta
fes_var <- (fes_ma$se^2)

  # Cluster sampling, Ni weights
k <- length(ex_1_data)
cs_est_N <- sum(ex_1_data$Ni*ex_1_data$g) / sum(ex_1_data$Ni)
  # RVE
Ai_N <- (1 - (ex_1_data$Ni / sum(ex_1_data$Ni)))^-2
cs_var_N <- sum(Ai_N*(ex_1_data$Ni^2)*((ex_1_data$g - cs_est_N)^2)) / (sum(ex_1_data$Ni)^2)

  # Cluster sampling, ni weights
cs_est_n <- sum(ex_1_data$ni*ex_1_data$g) / sum(ex_1_data$ni)
  # RVE
Ai_n <- (1 - (ex_1_data$ni / sum(ex_1_data$ni)))^-2
cs_var_n <- sum(Ai_n*(ex_1_data$ni^2)*((ex_1_data$g - cs_est_n)^2)) / (sum(ex_1_data$ni)^2)
```

# Example 2

```{r}
# Read in the data and calculate needed quantities - Table 6
ex_2_data <- read.csv("MTS_Ex2_cleaned.csv")

# Rename columns
names <- c("citation", "outcome", "type", "ni", "ni_t", "ni_c", "mean_t", "sd_t", "mean_c", "sd_c", "Ni")
colnames(ex_2_data) <- names

# Remove unecessary columns
ex_2_data <- ex_2_data[, !(names(ex_2_data) %in% c("outcome", "type"))]

# Add Hedge's g and its variance- calculate both d and j and get it from there
pooled_sd <- sqrt(((ex_2_data$sd_t^2)*(ex_2_data$ni_t - 1) + (ex_2_data$sd_c^2)*(ex_2_data$ni_c - 1)) / (ex_2_data$ni - 2))
d <- (ex_2_data$mean_t - ex_2_data$mean_c) / pooled_sd
var_d <- (ex_2_data$ni / (ex_2_data$ni_t*ex_2_data$ni_c)) + ((d^2) / (2*ex_2_data$ni))
j <- 1 - (3 / (4*(ex_2_data$ni - 2) - 1))
g <- d*j
vi <- (j^2) * var_d
ex_2_data$g <- g
ex_2_data$vi <- vi

# Weight percentages
fes_w <- 1 / vi
fes_w_perc <- (fes_w / sum(fes_w)) * 100
N_w <- ex_2_data$Ni
N_w_perc <- (N_w / sum(N_w)) * 100

# Perform the meta-analyses
# Original
orig_ma <- rma(yi=g, vi=vi, method="FE", data=ex_2_data)
orig_ma_est <- orig_ma$beta
orig_ma_var <- orig_ma$se^2

# Ni weights - manual
k <- length(ex_2_data)
N_est <- sum(ex_2_data$Ni*ex_2_data$g) / sum(ex_2_data$Ni)
  # RVE
Ai_N <- (1 - (ex_2_data$Ni / sum(ex_2_data$Ni)))^-2
N_var <- sum(Ai_N*(ex_2_data$Ni^2)*((ex_2_data$g - N_est)^2)) / (sum(ex_2_data$Ni)^2)
```
